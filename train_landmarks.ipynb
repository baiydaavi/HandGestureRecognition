{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_landmarks.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1X50fa4y7xi3Nd8kkYAMhGcKZrt4WTTXI","authorship_tag":"ABX9TyNTbimSYLleLVThFSRaXDe9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkLjFu-JUj8h","executionInfo":{"status":"ok","timestamp":1622932573378,"user_tz":420,"elapsed":152,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"7978284f-4df7-473f-d4db-cabb12486cec"},"source":["cd drive/MyDrive/github/HandGestureRecognition/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/github/HandGestureRecognition\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vwkqgwzm00XH","executionInfo":{"status":"ok","timestamp":1622932576983,"user_tz":420,"elapsed":2485,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch.nn.functional as F\n","from torch import optim\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"DExYUPRo-a8r","executionInfo":{"status":"ok","timestamp":1622932576985,"user_tz":420,"elapsed":4,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["LABEL_NAMES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n","          'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del',\n","          'space']"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkznEWCV-maJ","executionInfo":{"status":"ok","timestamp":1622932577634,"user_tz":420,"elapsed":3,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["class HGMDataset(Dataset):\n","  def __init__(self, csvpath):\n","    df = pd.read_csv(csvpath)\n","    df = df.sample(frac=1).reset_index(drop=True)       \n","    self.x = df.iloc[:,4:].values\n","    self.y = df['label'].values.reshape(-1,1)\n","\n","  def __len__(self):\n","    return len(self.y)\n","\n","  def __getitem__(self, idx):\n","    x_val  = torch.Tensor(self.x[idx])\n","    y_val  = torch.Tensor(self.y[idx])\n","    y_val  = y_val.type(torch.LongTensor)\n","    return { 'data': x_val,\n","            'target': y_val\n","            }"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5ckrFdDjtob","executionInfo":{"status":"ok","timestamp":1622932578244,"user_tz":420,"elapsed":3,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["# df = pd.read_csv('asl_alphabet_train/labels.csv')\n","# df = df.sample(frac=1).reset_index(drop=True)       \n","# x = df.iloc[:,4:].values\n","# y = df['label'].values.reshape(-1,1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YITPgwI1SEc8","executionInfo":{"status":"ok","timestamp":1622932581584,"user_tz":420,"elapsed":2739,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["HGM_data = HGMDataset('asl_alphabet_train/labels.csv')\n","#HGM_data.__getitem__(1)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZoMZmBk0WquR","executionInfo":{"status":"ok","timestamp":1622932581584,"user_tz":420,"elapsed":5,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["## create training and validation split \n","split = int(0.8 * len(HGM_data))\n","index_list = list(range(len(HGM_data)))\n","train_idx, valid_idx = index_list[:split], index_list[split:]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHt2sMFKWz4d","executionInfo":{"status":"ok","timestamp":1622932581585,"user_tz":420,"elapsed":5,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["## create sampler objects using SubsetRandomSampler\n","tr_sampler = SubsetRandomSampler(train_idx)\n","val_sampler = SubsetRandomSampler(valid_idx)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcBWdn1bW4-V","executionInfo":{"status":"ok","timestamp":1622932582793,"user_tz":420,"elapsed":2,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["## create iterator objects for train and valid datasets\n","trainloader = DataLoader(HGM_data, batch_size=64, sampler=tr_sampler)\n","validloader = DataLoader(HGM_data, batch_size=64, sampler=val_sampler)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"bj6Sp0aNXAOT","executionInfo":{"status":"ok","timestamp":1622932589101,"user_tz":420,"elapsed":144,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["class Model(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.hidden1 = nn.Linear(42, 256)\n","    self.hidden2 = nn.Linear(256, 128)\n","    self.output = nn.Linear(128, 28)\n","  \n","  def forward(self, x):\n","    x = self.hidden1(x)\n","    x = F.relu(x)\n","    x = self.hidden2(x)\n","    x = F.relu(x)\n","    x = self.output(x)\n","    return x"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"8YR0tcZMfJzz","executionInfo":{"status":"ok","timestamp":1622932590782,"user_tz":420,"elapsed":225,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["model = Model()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9JYvCEKVCMv","executionInfo":{"status":"ok","timestamp":1622932732756,"user_tz":420,"elapsed":615,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"0a46a070-2eb1-4f2a-8bf9-8bbb554569e9"},"source":["model.load_state_dict(torch.load('landmark_model_100.pth'))"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"al6m8s48Z4Kd"},"source":["loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay= 1e-6, momentum = 0.9, nesterov = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XlqBBeNaYuu","executionInfo":{"status":"ok","timestamp":1622888306081,"user_tz":420,"elapsed":224989,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"871b6ea7-a4b9-4b6d-b036-5692903bfd92"},"source":["epochs = 100\n","\n","for epoch in range(1, epochs+1): ## run the model for 100 epochs\n","  train_loss, valid_loss = [], []\n","\n","  ## training part \n","  model.train()\n","\n","  for _, batch in enumerate(trainloader):\n","      \n","    data, target = batch['data'], batch['target']\n","\n","    optimizer.zero_grad()\n","\n","    ## 1. forward propagation\n","    output = model(data)\n","\n","    ## 2. loss calculation\n","    loss = loss_function(output, target.squeeze(1))\n","\n","    ## 3. backward propagation\n","    loss.backward()\n","\n","    ## 4. weight optimization\n","    optimizer.step()\n","\n","    train_loss.append(loss.item())\n","      \n","  ## evaluation part \n","  model.eval()\n","\n","  for _, batch in enumerate(validloader):\n","\n","    data, target = batch['data'], batch['target']\n","    output = model(data)\n","    loss = loss_function(output, target.squeeze(1))\n","    valid_loss.append(loss.item())\n","\n","  print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))\n","\n","\n","torch.save(model.state_dict(), f'landmark_model_{epochs}.pth')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 1 Training Loss:  2.318478153518519 Valid Loss:  1.2544008037623238\n","Epoch: 2 Training Loss:  1.0001676783273354 Valid Loss:  0.7941928416490555\n","Epoch: 3 Training Loss:  0.6888530558980672 Valid Loss:  0.5962259871118208\n","Epoch: 4 Training Loss:  0.5529661241666054 Valid Loss:  0.525073784151498\n","Epoch: 5 Training Loss:  0.4867507097116262 Valid Loss:  0.46909551226040896\n","Epoch: 6 Training Loss:  0.44313140903602305 Valid Loss:  0.43040452888783287\n","Epoch: 7 Training Loss:  0.40904973792379234 Valid Loss:  0.40509174492429284\n","Epoch: 8 Training Loss:  0.38294233472957373 Valid Loss:  0.37793362973367467\n","Epoch: 9 Training Loss:  0.36055077380530953 Valid Loss:  0.3591895947999814\n","Epoch: 10 Training Loss:  0.341571423508073 Valid Loss:  0.3498428413534866\n","Epoch: 11 Training Loss:  0.325778055342689 Valid Loss:  0.3299587445004898\n","Epoch: 12 Training Loss:  0.31177483567182296 Valid Loss:  0.31511546822593495\n","Epoch: 13 Training Loss:  0.2998406714416359 Valid Loss:  0.30804373201201946\n","Epoch: 14 Training Loss:  0.2888644580347436 Valid Loss:  0.29384957911337123\n","Epoch: 15 Training Loss:  0.27932279893254813 Valid Loss:  0.2928013036137118\n","Epoch: 16 Training Loss:  0.2723399920218726 Valid Loss:  0.2874191496740369\n","Epoch: 17 Training Loss:  0.2653256262100376 Valid Loss:  0.27150072968181443\n","Epoch: 18 Training Loss:  0.25760716011962004 Valid Loss:  0.27062802152598603\n","Epoch: 19 Training Loss:  0.2522735325399797 Valid Loss:  0.2586090119446025\n","Epoch: 20 Training Loss:  0.24598701930657074 Valid Loss:  0.25641487514709727\n","Epoch: 21 Training Loss:  0.2403645529233161 Valid Loss:  0.254837821774623\n","Epoch: 22 Training Loss:  0.23553272079028034 Valid Loss:  0.2547438305528725\n","Epoch: 23 Training Loss:  0.2310845150961197 Valid Loss:  0.24248749374905054\n","Epoch: 24 Training Loss:  0.2259534251736065 Valid Loss:  0.2394285818452344\n","Epoch: 25 Training Loss:  0.22272721163181253 Valid Loss:  0.23767030328950461\n","Epoch: 26 Training Loss:  0.21861980025516412 Valid Loss:  0.23567122591330725\n","Epoch: 27 Training Loss:  0.21493915960764112 Valid Loss:  0.23536294742542155\n","Epoch: 28 Training Loss:  0.21095951093267376 Valid Loss:  0.2286078902290148\n","Epoch: 29 Training Loss:  0.20755936659235166 Valid Loss:  0.22856080856393365\n","Epoch: 30 Training Loss:  0.20431841588180766 Valid Loss:  0.22225643039187964\n","Epoch: 31 Training Loss:  0.2013067737617324 Valid Loss:  0.22217290738926215\n","Epoch: 32 Training Loss:  0.19724226891335134 Valid Loss:  0.21389477719717165\n","Epoch: 33 Training Loss:  0.19483186686164247 Valid Loss:  0.22173823496217238\n","Epoch: 34 Training Loss:  0.1926454043861995 Valid Loss:  0.21536410917692325\n","Epoch: 35 Training Loss:  0.19083462957193895 Valid Loss:  0.20979793952668416\n","Epoch: 36 Training Loss:  0.18731863020608822 Valid Loss:  0.20917549683328937\n","Epoch: 37 Training Loss:  0.1838286356852118 Valid Loss:  0.20963082042358377\n","Epoch: 38 Training Loss:  0.18240120961635778 Valid Loss:  0.2084644687745501\n","Epoch: 39 Training Loss:  0.17980450155504685 Valid Loss:  0.2078773572602693\n","Epoch: 40 Training Loss:  0.178376682110922 Valid Loss:  0.20805845094077727\n","Epoch: 41 Training Loss:  0.17519832222659285 Valid Loss:  0.19968566706075389\n","Epoch: 42 Training Loss:  0.17356743943770375 Valid Loss:  0.2012827667462475\n","Epoch: 43 Training Loss:  0.17139873566974098 Valid Loss:  0.19459726014996276\n","Epoch: 44 Training Loss:  0.16943915354796743 Valid Loss:  0.1931945325478035\n","Epoch: 45 Training Loss:  0.16696695219120972 Valid Loss:  0.19493646826595068\n","Epoch: 46 Training Loss:  0.165722717017287 Valid Loss:  0.19823988347369081\n","Epoch: 47 Training Loss:  0.16358238492424773 Valid Loss:  0.19153786161914468\n","Epoch: 48 Training Loss:  0.16165054245277755 Valid Loss:  0.1901174817179494\n","Epoch: 49 Training Loss:  0.1604783506981567 Valid Loss:  0.18768951391034266\n","Epoch: 50 Training Loss:  0.15784510282887515 Valid Loss:  0.18786672192680484\n","Epoch: 51 Training Loss:  0.1564848451850425 Valid Loss:  0.18732694791739476\n","Epoch: 52 Training Loss:  0.15481770451793278 Valid Loss:  0.18786014742491877\n","Epoch: 53 Training Loss:  0.15375344685325537 Valid Loss:  0.1891756556709023\n","Epoch: 54 Training Loss:  0.15171044696243288 Valid Loss:  0.1830271559603074\n","Epoch: 55 Training Loss:  0.1493172301364112 Valid Loss:  0.1864047431113089\n","Epoch: 56 Training Loss:  0.14878791138518788 Valid Loss:  0.18657238384818328\n","Epoch: 57 Training Loss:  0.14715718029885605 Valid Loss:  0.18027895680245232\n","Epoch: 58 Training Loss:  0.14574554402128434 Valid Loss:  0.18547084388487478\n","Epoch: 59 Training Loss:  0.1433054380775443 Valid Loss:  0.17836122505695504\n","Epoch: 60 Training Loss:  0.1418740861474984 Valid Loss:  0.17609149754485665\n","Epoch: 61 Training Loss:  0.14145490036491623 Valid Loss:  0.17357609714107478\n","Epoch: 62 Training Loss:  0.14034943808430592 Valid Loss:  0.17569420243449071\n","Epoch: 63 Training Loss:  0.13914590132090326 Valid Loss:  0.17013920062933774\n","Epoch: 64 Training Loss:  0.13795290850130373 Valid Loss:  0.17357862111838424\n","Epoch: 65 Training Loss:  0.13651930075138807 Valid Loss:  0.18333776357638484\n","Epoch: 66 Training Loss:  0.1358278750093066 Valid Loss:  0.16935080138089903\n","Epoch: 67 Training Loss:  0.13326245491670385 Valid Loss:  0.1703085343956071\n","Epoch: 68 Training Loss:  0.1323642634146553 Valid Loss:  0.16652235988637104\n","Epoch: 69 Training Loss:  0.13129440753220697 Valid Loss:  0.17008566898019875\n","Epoch: 70 Training Loss:  0.1317647608123434 Valid Loss:  0.16499788256581216\n","Epoch: 71 Training Loss:  0.1295466533296118 Valid Loss:  0.16699631557635525\n","Epoch: 72 Training Loss:  0.12833632503610082 Valid Loss:  0.16976344055112672\n","Epoch: 73 Training Loss:  0.12639941482400868 Valid Loss:  0.16747178146067787\n","Epoch: 74 Training Loss:  0.12612883629058255 Valid Loss:  0.1641245492870974\n","Epoch: 75 Training Loss:  0.12489622807992859 Valid Loss:  0.167376748395755\n","Epoch: 76 Training Loss:  0.1246141001793685 Valid Loss:  0.16308798416353323\n","Epoch: 77 Training Loss:  0.12219356621339489 Valid Loss:  0.16913265453870682\n","Epoch: 78 Training Loss:  0.12167817931505508 Valid Loss:  0.1626345870180932\n","Epoch: 79 Training Loss:  0.12056695093238688 Valid Loss:  0.1651960293050198\n","Epoch: 80 Training Loss:  0.11910845511826441 Valid Loss:  0.16468142413205522\n","Epoch: 81 Training Loss:  0.11835540182116526 Valid Loss:  0.1609274106702822\n","Epoch: 82 Training Loss:  0.11752057171517373 Valid Loss:  0.16621233084622553\n","Epoch: 83 Training Loss:  0.11814816155921459 Valid Loss:  0.1605475101291257\n","Epoch: 84 Training Loss:  0.1160291228306021 Valid Loss:  0.1568940797382418\n","Epoch: 85 Training Loss:  0.1140442611402808 Valid Loss:  0.16728679137304425\n","Epoch: 86 Training Loss:  0.11329561435881244 Valid Loss:  0.1617946738103295\n","Epoch: 87 Training Loss:  0.11246405624932881 Valid Loss:  0.15804580255301998\n","Epoch: 88 Training Loss:  0.11195566839810493 Valid Loss:  0.16395411571378218\n","Epoch: 89 Training Loss:  0.11059179973093501 Valid Loss:  0.1619607754818657\n","Epoch: 90 Training Loss:  0.11169465446973818 Valid Loss:  0.16020263950066532\n","Epoch: 91 Training Loss:  0.11005090564972883 Valid Loss:  0.168982120603323\n","Epoch: 92 Training Loss:  0.10876079765903958 Valid Loss:  0.15632264617392244\n","Epoch: 93 Training Loss:  0.10676028028097564 Valid Loss:  0.1603522690382841\n","Epoch: 94 Training Loss:  0.10689951035923498 Valid Loss:  0.1563469942604356\n","Epoch: 95 Training Loss:  0.10570101685489591 Valid Loss:  0.15893886701532584\n","Epoch: 96 Training Loss:  0.1059942059363115 Valid Loss:  0.15923033495543196\n","Epoch: 97 Training Loss:  0.10480905010757809 Valid Loss:  0.15441641356686459\n","Epoch: 98 Training Loss:  0.1035367173587788 Valid Loss:  0.15349382531062206\n","Epoch: 99 Training Loss:  0.10368215298598803 Valid Loss:  0.15753447192529327\n","Epoch: 100 Training Loss:  0.10225720486121533 Valid Loss:  0.1551447607220753\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnnzYGyca0vp","executionInfo":{"status":"ok","timestamp":1622932742196,"user_tz":420,"elapsed":141,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"530dea04-c23b-4b7e-80a8-68b8394777dd"},"source":["## dataloader for validation dataset \n","dataiter = iter(validloader)\n","batch = dataiter.next()\n","data, labels = batch['data'], batch['target']\n","output = model(data)\n","\n","_, preds_tensor = torch.max(output, 1)\n","preds = np.squeeze(preds_tensor.numpy())\n","\n","print (\"Actual:\", labels.numpy().reshape(-1)[:10])\n","print (\"Predicted:\", preds[:10])\n","\n","print(preds[:10] == labels.numpy().reshape(-1)[:10])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Actual: [ 8 25 19  9 24 25 18 20 25  2]\n","Predicted: [ 8 25 19  9 24 25 18 20 25  2]\n","[ True  True  True  True  True  True  True  True  True  True]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"39H_vVCDyvyh","executionInfo":{"status":"ok","timestamp":1622932890701,"user_tz":420,"elapsed":752,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["df = pd.read_csv('asl_alphabet_train/labels.csv')\n","df = df.sample(frac=1).reset_index(drop=True)       \n","x = df.iloc[:,4:].values\n","y = df['label'].values.reshape(-1,1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhPEYaYIVocX","executionInfo":{"status":"ok","timestamp":1622932897712,"user_tz":420,"elapsed":4,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"27900f6e-688e-45a7-ebc8-f47a1111faa8"},"source":["x[1]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.        ,  0.        ,  0.05786228, -0.06654346,  0.08304906,\n","       -0.14307708,  0.03804433, -0.19017434, -0.02180761, -0.21233875,\n","        0.05042607, -0.25779331,  0.03899133, -0.35060331,  0.02406031,\n","       -0.4007701 ,  0.00922436, -0.44758731, -0.00900739, -0.23962307,\n","       -0.01581275, -0.34495968, -0.01314265, -0.39164561, -0.00930548,\n","       -0.42453092, -0.06065243, -0.19943136, -0.0396719 , -0.21733195,\n","       -0.01066726, -0.16074717, -0.00620383, -0.14255244, -0.1006099 ,\n","       -0.14959776, -0.0787648 , -0.17250925, -0.04910809, -0.1371786 ,\n","       -0.04196107, -0.11914754])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GemVnPDaVr5Y","executionInfo":{"status":"ok","timestamp":1622933311499,"user_tz":420,"elapsed":145,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"ea599063-dd5b-45a9-a0d0-e0f25877578b"},"source":["output = model(torch.tensor(x[1]).type(torch.FloatTensor))\n","output "],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ -7.0216,   6.0504, -12.7404,   8.0520,  -5.4963, -13.0640,   2.1838,\n","          8.2303,   4.5476,   2.6291,   8.7274,  -3.2178,  -0.3508,   9.9614,\n","        -13.8822,  -2.9866, -18.4252,  16.3872,   4.8337, -10.5987,  18.4459,\n","         10.7970,   8.6792,   5.0900, -14.3952, -13.2475,  -0.6711,  -3.9275],\n","       grad_fn=<AddBackward0>)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6pUiD-JVzT9","executionInfo":{"status":"ok","timestamp":1622933437851,"user_tz":420,"elapsed":140,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"d22ba0f3-a72d-40a9-b9de-5b3ca4afb8c9"},"source":["np.argmax(output.detach().numpy())"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqaXCLlNXHVR","executionInfo":{"status":"ok","timestamp":1622933452694,"user_tz":420,"elapsed":163,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"5f4f250d-5ddd-421c-fac1-9cb9cd32036e"},"source":["y[1]"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([20])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"jZF1FZTyXzWg"},"source":[""],"execution_count":null,"outputs":[]}]}