{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ColabDNNLandmarksTrain.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5R91hFtevDp","executionInfo":{"status":"ok","timestamp":1627096063353,"user_tz":420,"elapsed":29683,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"9f6dc027-9c16-4017-db1e-9056982274d0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VSDy0mC9e0Wl","executionInfo":{"status":"ok","timestamp":1627096359711,"user_tz":420,"elapsed":125,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"66942ebe-b95a-4f95-e108-273effffc00e"},"source":["# Change drive location from Colab\n","%cd drive/MyDrive/github/HandGestureRecognition/HandLandmarkModel"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/github/HandGestureRecognition/HandLandmarkModel\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vwkqgwzm00XH","executionInfo":{"status":"ok","timestamp":1627096367774,"user_tz":420,"elapsed":1355,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["from os import path\n","\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch.nn.functional as F\n","import torch.utils.tensorboard as tb\n","from torch import optim\n","\n","from model import DNN_Landmark_Model\n","from utils import ConfusionMatrix"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkznEWCV-maJ","executionInfo":{"status":"ok","timestamp":1627096787744,"user_tz":420,"elapsed":176,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["## create the Dataset class without normalization\n","class HGMDataset(Dataset):\n","  def __init__(self, csvpath):\n","    df = pd.read_csv(csvpath)\n","    df = df.sample(frac=1).reset_index(drop=True)       \n","    self.x = df.iloc[:,4:].values\n","    self.y = df['label'].values.reshape(-1,1)\n","\n","  def __len__(self):\n","    return len(self.y)\n","\n","  def __getitem__(self, idx):\n","    x_val  = torch.Tensor(self.x[idx])\n","    y_val  = torch.Tensor(self.y[idx])\n","    y_val  = y_val.type(torch.LongTensor)\n","    return { 'data': x_val,\n","            'target': y_val\n","            }\n","\n","## create the Dataset class with normalization\n","class NormHGMDataset(Dataset):\n","  def __init__(self, csvpath):\n","    df = pd.read_csv(csvpath)\n","\n","    x_norm = [f'x_{i}' for i in range(21)]\n","    y_norm = [f'y_{i}' for i in range(21)]\n","\n","    df_x = df[x_norm]\n","    df_y = df[y_norm]\n","\n","    df_x = df_x.subtract(df_x.min(axis=1), axis=0)\n","    df_x = df_x.div(df_x.max(axis=1), axis=0)\n","\n","    df_y = df_y.subtract(df_y.min(axis=1), axis=0)\n","    df_y = df_y.div(df_y.max(axis=1), axis=0)\n","\n","    df[x_norm] = df_x\n","    df[y_norm] = df_y\n","    \n","    df = df.sample(frac=1).reset_index(drop=True)       \n","    self.x = df.iloc[:,4:].values\n","    self.y = df['label'].values.reshape(-1,1)\n","\n","  def __len__(self):\n","    return len(self.y)\n","\n","  def __getitem__(self, idx):\n","    x_val  = torch.Tensor(self.x[idx])\n","    y_val  = torch.Tensor(self.y[idx])\n","    y_val  = y_val.type(torch.LongTensor)\n","    return { 'data': x_val,\n","            'target': y_val\n","            }"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"YITPgwI1SEc8"},"source":["## create the non-normalized Dataset object\n","# HGM_data = HGMDataset('asl_alphabet_train/labels.csv')\n","\n","## create the normalizaed Dataset object\n","HGM_data = NormHGMDataset('asl_alphabet_train/labels.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZoMZmBk0WquR"},"source":["## create training and validation split \n","split = int(0.8 * len(HGM_data))\n","index_list = list(range(len(HGM_data)))\n","train_idx, valid_idx = index_list[:split], index_list[split:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHt2sMFKWz4d"},"source":["## create sampler objects using SubsetRandomSampler\n","tr_sampler = SubsetRandomSampler(train_idx)\n","val_sampler = SubsetRandomSampler(valid_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcBWdn1bW4-V"},"source":["## create iterator objects for train and valid datasets\n","trainloader = DataLoader(HGM_data, batch_size=256, sampler=tr_sampler)\n","validloader = DataLoader(HGM_data, batch_size=256, sampler=val_sampler)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8YR0tcZMfJzz","executionInfo":{"status":"ok","timestamp":1627098077775,"user_tz":420,"elapsed":112,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["## initialize the model\n","model = DNN_Landmark_Model()"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"al6m8s48Z4Kd"},"source":["## choose loss function and optimizer \n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay= 1e-6, momentum = 0.9, nesterov = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6XlqBBeNaYuu"},"source":["## train the model\n","epochs = 2000\n","\n","for epoch in range(1, epochs+1):\n","\n","    train_loss, valid_loss = [], []\n","    train_confusionMatrix = ConfusionMatrix()\n","    valid_confusionMatrix = ConfusionMatrix()\n","\n","    ## training part \n","    model.train()\n","\n","    for _, batch in enumerate(trainloader):\n","        \n","        data, target = batch['data'], batch['target']\n","\n","        optimizer.zero_grad()\n","\n","        ## 1. forward propagation\n","        output = model(data)\n","\n","        train_confusionMatrix.add(output.argmax(1), target.squeeze(1))\n","\n","        ## 2. loss calculation\n","        loss = loss_function(output, target.squeeze(1))\n","\n","        ## 3. backward propagation\n","        loss.backward()\n","\n","        ## 4. weight optimization\n","        optimizer.step()\n","\n","        ## 5. log train loss   \n","        train_loss.append(loss.item())\n","        \n","    ## validation part \n","    model.eval()\n","\n","    for _, batch in enumerate(validloader):\n","\n","        data, target = batch['data'], batch['target']\n","        output = model(data)\n","        valid_confusionMatrix.add(output.argmax(1), target.squeeze(1))\n","        loss = loss_function(output, target.squeeze(1))\n","        valid_loss.append(loss.item())\n","\n","    \n","    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss),\n","           \"Training Acc: \", train_confusionMatrix.global_accuracy, \n","           \"Valid Loss: \", np.mean(valid_loss),\n","           \"Valid Acc: \", valid_confusionMatrix.global_accuracy,\n","           )\n","    \n","    # if epoch%100 == 0 and epoch != 0:\n","    #     torch.save(model.state_dict(), f'trained_landmarks_models/DNN_landmarks_model_{epoch}.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Trqd8nzubqKq"},"source":["## save model\n","torch.save(model.state_dict(), f'trained_landmarks_models/Normalized_DNN_landmarks_model.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3a1F3dx-mFSt"},"source":["#Testing on unseen data"]},{"cell_type":"code","metadata":{"id":"JLgRROval2jX","executionInfo":{"status":"ok","timestamp":1627098071899,"user_tz":420,"elapsed":117,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["# labels array\n","labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', \n","          'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V','W', 'X', \n","          'Y', 'Z', 'delete', 'space']"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"qG4Pcp7QnRwl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627098082229,"user_tz":420,"elapsed":142,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"4dadccd5-24e7-4190-d8a2-975961d6a6da"},"source":["# load trained model\n","model.load_state_dict(torch.load('trained_landmarks_models/Normalized_DNN_landmarks_model.pth'))"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"xNo2T-Osh-qa","executionInfo":{"status":"ok","timestamp":1627098083916,"user_tz":420,"elapsed":2,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}}},"source":["## create the normalizaed Test Dataset object\n","HGM_test_data = NormHGMDataset('asl_alphabet_test/labels.csv')\n","testloader = DataLoader(HGM_test_data)\n","dataiter = iter(testloader)"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_KvDKdLi92I","executionInfo":{"status":"ok","timestamp":1627098113116,"user_tz":420,"elapsed":142,"user":{"displayName":"Avinash","photoUrl":"","userId":"03822310646586674578"}},"outputId":"cf40213c-6c0a-4a64-ecc3-917a9fda9e6d"},"source":["# Print test results\n","while True:\n","    try:\n","        test_image = dataiter.next()\n","    except:\n","        break\n","    data, label = test_image['data'], test_image['target']\n","    output = model(data)\n","    _, preds_tensor = torch.max(output, 1)\n","    pred = np.squeeze(preds_tensor.numpy())\n","    actual = np.squeeze(label.numpy())\n","    print(f'Actual sign: {labels[actual]}, Predicted sign : {labels[pred]}')"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Actual sign: U, Predicted sign : U\n","Actual sign: E, Predicted sign : E\n","Actual sign: H, Predicted sign : H\n","Actual sign: B, Predicted sign : B\n","Actual sign: Z, Predicted sign : Z\n","Actual sign: V, Predicted sign : V\n","Actual sign: C, Predicted sign : C\n","Actual sign: M, Predicted sign : M\n","Actual sign: T, Predicted sign : T\n","Actual sign: K, Predicted sign : K\n","Actual sign: Y, Predicted sign : Y\n","Actual sign: F, Predicted sign : F\n","Actual sign: D, Predicted sign : D\n","Actual sign: N, Predicted sign : M\n","Actual sign: O, Predicted sign : O\n","Actual sign: I, Predicted sign : I\n","Actual sign: L, Predicted sign : L\n","Actual sign: Q, Predicted sign : Q\n","Actual sign: R, Predicted sign : R\n","Actual sign: P, Predicted sign : P\n","Actual sign: X, Predicted sign : X\n","Actual sign: G, Predicted sign : G\n","Actual sign: J, Predicted sign : J\n","Actual sign: A, Predicted sign : A\n","Actual sign: W, Predicted sign : W\n","Actual sign: S, Predicted sign : S\n"],"name":"stdout"}]}]}