{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "\n",
     "\n",
     "import torch\n",
     "import torch.nn as nn\n",
     "import torchvision.transforms as transforms\n",
     "import torch.nn.functional as F\n",
     "import sklearn\n",
     "from sklearn.model_selection import train_test_split\n",
     "from sklearn.preprocessing import LabelEncoder\n",
     "from sklearn.preprocessing import OneHotEncoder\n",
     "import numpy as np\n",
     "import pandas as pd\n",
     "import os\n",
     "import matplotlib.pyplot as plt\n",
     "import PIL\n",
     "from PIL import Image\n",
     "import albumentations as A\n",
     "from albumentations.pytorch import ToTensorV2\n",
     "import seaborn as sns\n",
     "import glob\n",
     "from pathlib import Path\n",
     "torch.manual_seed(1)\n",
     "np.random.seed(1)\n",
     "import os\n",
     "\n",
     "\n",
     "\n",
     "train_path = '/Users/asinha4/kaggle/HandGestureRecognition/asl_alphabet_train'\n",
     "test_path = '/Users/asinha4/kaggle/HandGestureRecognition/asl_alphabet_test'\n",
     "classes = os.listdir(train_path)\n",
     "train_images = []\n",
     "train_labels = []\n",
     "test_images = []\n",
     "test_labels = []\n",
     "for c in classes:\n",
     "    flist = os.listdir(train_path + '/' + c)\n",
     "    for file in flist:\n",
     "        file_path = os.path.join(train_path, c, file)\n",
     "        train_images.append(file_path)\n",
     "        train_labels.append(c)\n",
     "testflist = os.listdir(test_path)\n",
     "for file in testflist:\n",
     "    file_path = os.path.join(test_path, file)\n",
     "    test_images.append(file_path)\n",
     "    test_label = file.split('_')[0]\n",
     "    test_labels.append(test_label)\n",
     "\n",
     "\n",
     "train_images = pd.Series(train_images, name='file_paths')\n",
     "train_labels = pd.Series(train_labels, name='labels')\n",
     "test_images = pd.Series(test_images, name='file_paths')\n",
     "test_labels = pd.Series(test_labels, name='labels')\n",
     "train_df = pd.DataFrame(pd.concat([train_images, train_labels], axis=1))\n",
     "test_df = pd.DataFrame(pd.concat([test_images, test_labels], axis=1))\n",
     "train_df\n",
     "\n",
     "\n",
     "# **Visualize Images**\n",
     "\n",
     "\n",
     "plt.figure(figsize=(14, 10))\n",
     "for i in range(20):\n",
     "    idx = np.random.randint(0, len(train_df) - 1)\n",
     "    plt.subplot(4, 5, i+1)\n",
     "    img = train_df.iloc[idx, 0]\n",
     "    plt.imshow(plt.imread(img))\n",
     "    plt.title(train_df.iloc[idx, 1], size=10, color=\"black\") \n",
     "    plt.xticks([])\n",
     "    plt.yticks([])\n",
     "    \n",
     "plt.show()\n",
     "\n",
     "\n",
     "# **Split Train Dataframe into Train and Valid**\n",
     "\n",
     "\n",
     "train_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)\n",
     "print(train_df['labels'].value_counts())\n",
     "print(valid_df['labels'].value_counts())\n",
     "\n",
     "\n",
     "# **Encode Labels**\n",
     "\n",
     "\n",
     "lb = LabelEncoder()\n",
     "train_df['encoded_labels'] = lb.fit_transform(train_df['labels'])\n",
     "valid_df['encoded_labels'] = lb.fit_transform(valid_df['labels'])\n",
     "test_df['encoded_labels'] = lb.fit_transform(test_df['labels'])\n",
     "train_df\n",
     "\n",
     "\n",
     "# **Dataset Class**\n",
     "\n",
     "\n",
     "class ASLAlphabet(torch.utils.data.Dataset):\n",
     "    def __init__(self, df=train_df, transform=transforms.Compose([transforms.ToTensor()])):\n",
     "        self.df = df\n",
     "        self.transform = transform\n",
     "    \n",
     "    def __len__(self):\n",
     "        length = len(self.df)\n",
     "        return length\n",
     "    \n",
     "    def __getitem__(self, idx):\n",
     "        img_path = self.df.iloc[idx, 0]\n",
     "        label = self.df.iloc[idx, 2]\n",
     "        label = torch.tensor(label)\n",
     "        image = Image.open(img_path).convert('RGB')\n",
     "        img = np.array(image)\n",
     "        image = self.transform(image=img)[\"image\"]\n",
     "        return image, label\n",
     "\n",
     "\n",
     "train_transforms = A.Compose([\n",
     "    #No need to resize images since they are all 200 x 200 x 3\n",
     "    A.GaussNoise(),\n",
     "    A.Blur(),\n",
     "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
     "    ToTensorV2()\n",
     "])\n",
     "\n",
     "test_transforms = A.Compose([\n",
     "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
     "    ToTensorV2()\n",
     "])\n",
     "\n",
     "\n",
     "train_dataset = ASLAlphabet(df=train_df, transform=train_transforms)\n",
     "valid_dataset = ASLAlphabet(df=valid_df, transform=test_transforms)\n",
     "test_dataset = ASLAlphabet(df=test_df, transform=test_transforms)\n",
     "\n",
     "\n",
     "batch_size=64\n",
     "\n",
     "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
     "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size)\n",
     "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset))\n",
     "\n",
     "\n",
     "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
     "device\n",
     "\n",
     "\n",
     "# **Model Architecture**\n",
     "\n",
     "\n",
     "class SimpleCNN(nn.Module):\n",
     "    def __init__(self):\n",
     "        super().__init__()\n",
     "        self.layer1 = nn.Sequential(\n",
     "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
     "            nn.BatchNorm2d(16),\n",
     "            nn.LeakyReLU(0.1))\n",
     "        \n",
     "        self.layer2 = nn.Sequential(\n",
     "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
     "            nn.BatchNorm2d(32),\n",
     "            nn.LeakyReLU(0.1),\n",
     "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
     "        \n",
     "        self.fc = nn.Sequential(\n",
     "            nn.Linear(32 * 100 * 100, 81),\n",
     "            nn.Dropout(0.2),\n",
     "            nn.BatchNorm1d(81),\n",
     "            nn.LeakyReLU(81, 29))\n",
     "        \n",
     "    def forward(self, x):\n",
     "        x = self.layer1(x)\n",
     "        x = self.layer2(x)\n",
     "        x = x.view(-1, 32 * 100 * 100)\n",
     "        x = self.fc(x)\n",
     "        return x\n",
     "\n",
     "\n",
     "# **Training**\n",
     "\n",
     "#From https://github.com/Bjarten/early-stopping-pytorch\n",
     "class EarlyStopping:\n",
     "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
     "    def __init__(self, patience=7, verbose=False):\n",
     "        \"\"\"\n",
     "        Args:\n",
     "            patience (int): How long to wait after last time validation loss improved.\n",
     "                            Default: 7\n",
     "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
     "                            Default: False\n",
     "        \"\"\"\n",
     "        self.patience = patience\n",
     "        self.verbose = verbose\n",
     "        self.counter = 0\n",
     "        self.best_score = None\n",
     "        self.early_stop = False\n",
     "        self.val_loss_min = np.Inf\n",
     "\n",
     "    def __call__(self, val_loss, model):\n",
     "\n",
     "        score = -val_loss\n",
     "\n",
     "        if self.best_score is None:\n",
     "            self.best_score = score\n",
     "        elif score < self.best_score:\n",
     "            self.counter += 1\n",
     "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
     "            if self.counter >= self.patience:\n",
     "                self.early_stop = True\n",
     "        else:\n",
     "            self.best_score = score\n",
     "            self.counter = 0\n",
     "\n",
     "\n",
     "model = SimpleCNN()\n",
     "\n",
     "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
     "\n",
     "criterion = nn.CrossEntropyLoss()\n",
     "\n",
     "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, cooldown=2, verbose=True)\n",
     "\n",
     "\n",
     "model = model.to(device)\n",
     "criterion = criterion.to(device)\n",
     "\n",
     "\n",
     "epochs = 30\n",
     "\n",
     "total_train_loss = []\n",
     "total_valid_loss = []\n",
     "best_valid_loss = np.Inf\n",
     "early_stop = EarlyStopping(patience=5, verbose=True)\n",
     "\n",
     "for epoch in range(epochs): \n",
     "    print('Epoch: ', epoch + 1)\n",
     "    train_loss = []\n",
     "    valid_loss = []\n",
     "    train_correct = 0\n",
     "    train_total = 0\n",
     "    valid_correct = 0\n",
     "    valid_total = 0\n",
     "    for image, target in train_loader:\n",
     "        model.train()\n",
     "        image, target = image.to(device), target.to(device)\n",
     "        \n",
     "        optimizer.zero_grad()\n",
     "        output = model(image)\n",
     "        loss = criterion(output, target)\n",
     "        train_loss.append(loss.item())\n",
     "        _, predicted = torch.max(output.data, 1)\n",
     "        train_total += target.size(0)\n",
     "        train_correct += (predicted == target).sum().item()\n",
     "        \n",
     "        loss.backward()\n",
     "        optimizer.step()\n",
     "        \n",
     "    for image, target in valid_loader:\n",
     "        with torch.no_grad():\n",
     "            model.eval()\n",
     "            image, target = image.to(device), target.to(device)\n",
     "            \n",
     "            output = model(image)\n",
     "            loss = criterion(output, target)\n",
     "            valid_loss.append(loss.item())\n",
     "            _, predicted = torch.max(output.data, 1)\n",
     "            valid_total += target.size(0)\n",
     "            valid_correct += (predicted == target).sum().item()\n",
     "            \n",
     "    epoch_train_loss = np.mean(train_loss)\n",
     "    epoch_valid_loss = np.mean(valid_loss)\n",
     "    print(f'Epoch {epoch + 1}, train loss: {epoch_train_loss:.4f}, valid loss: {epoch_valid_loss:.4f}, train accuracy: {(100 * train_correct / train_total):.4f}%, valid accuracy: {(100 * valid_correct / valid_total):.4f}%')\n",
     "    if epoch_valid_loss < best_valid_loss:\n",
     "        torch.save(model.state_dict(), 'asl_model.pth')\n",
     "        print('Model improved. Saving model.')\n",
     "        best_valid_loss = epoch_valid_loss\n",
     "    \n",
     "    early_stop(epoch_valid_loss, model)\n",
     "        \n",
     "    if early_stop.early_stop:\n",
     "        print(\"Early stopping\")\n",
     "        break\n",
     "        \n",
     "    lr_scheduler.step(epoch_valid_loss)\n",
     "    total_train_loss.append(epoch_train_loss)\n",
     "    total_valid_loss.append(epoch_valid_loss)\n",
     "\n",
     "\n",
     "# **Predictions on Test Set**\n",
     "\n",
     "\n",
     "model.load_state_dict(torch.load('asl_model.pth'))\n",
     "\n",
     "correct = 0\n",
     "total = 0\n",
     "\n",
     "with torch.no_grad():\n",
     "    model.eval()\n",
     "    for image, target in test_loader:\n",
     "        image, target = image.to(device), target.to(device)\n",
     "        \n",
     "        output = model(image)\n",
     "        \n",
     "        _, predicted = torch.max(output.data, 1)\n",
     "        total += target.size(0)\n",
     "        correct += (predicted == target).sum().item()\n",
     "\n",
     "print('Test Accuracy: %d %%' % (\n",
     "    100 * correct / total))\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": []
}